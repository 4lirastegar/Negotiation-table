# LLM Negotiation Arena

Multi-Agent Negotiation Simulation using Large Language Models

## Project Structure

```
nlp/
â”œâ”€â”€ scenarios/          # JSON files for negotiation scenarios
â”œâ”€â”€ personas/           # Persona definitions and management
â”œâ”€â”€ agents/            # Agent classes and LLM integration
â”œâ”€â”€ simulation/        # Negotiation engine and loop
â”œâ”€â”€ analysis/          # Academic metrics and batch testing
â”œâ”€â”€ utils/             # Helper functions (MongoDB, scenario loader)
â”œâ”€â”€ config/            # Configuration files
â”œâ”€â”€ app.py             # Streamlit website (main entry)
â””â”€â”€ requirements.txt   # Python dependencies
```

## Setup

### 1. Virtual Environment

To activate the virtual environment:

```bash
source venv/bin/activate
```

To deactivate:

```bash
deactivate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure API Keys and Database

1. Copy the template file:
   ```bash
   cp env.template .env
   ```

2. Edit `.env` and add your credentials:
   - `OPENAI_API_KEY` (if using OpenAI)
   - `ANTHROPIC_API_KEY` (if using Anthropic)
   - `DB_NAME`, `DB_USER`, `DB_PASS`, `DB_HOST` (MongoDB credentials)

3. Test MongoDB connection (optional):
   ```bash
   python test_mongodb.py
   ```

### 4. Run the Application

```bash
streamlit run app.py
```

## Features

- ğŸ¤– **Multi-Agent Negotiation**: LLM-powered agents with distinct personalities
- ğŸ­ **Diverse Personas**: 8 personalities (Aggressive, Fair, Liar, Logical, Cooperative, Stubborn, Desperate, Strategic)
- ğŸ“Š **Real-time Visualization**: Watch negotiations unfold live in the browser
- âš–ï¸ **Judge as Referee**: LLM checks for agreement after each round
- ğŸ’¾ **MongoDB Integration**: All negotiations saved for analysis
- ğŸ“ˆ **Academic Metrics**: Agreement rate, rounds to convergence, utility scores, language complexity
- ğŸ§ª **Batch Testing**: Run multiple negotiations automatically for statistical analysis
- ğŸ”¬ **Objective Analysis**: Mathematical calculations, not LLM opinions

## Status

âœ… Step 1: Project Structure Setup - Complete  
âœ… Step 2: Scenario System - Complete  
âœ… Step 3: Persona System (Minimal, Emergent) - Complete  
âœ… Step 4: Base Agent Class - Complete  
âœ… Step 5: Negotiation Engine (Real-time Referee) - Complete  
âœ… Step 6: Judge System (Factual Detection Only) - Complete  
âœ… Step 7: Streamlit Website - Complete  
âœ… Step 8: MongoDB Integration - Complete  
âœ… Step 9: Academic Metrics Implementation - Complete  
âœ… Step 10: Batch Testing System - Complete  
âœ… Step 11: Language Complexity Analysis - Complete

## Academic Metrics

### Run Batch Testing:
```bash
python analysis/batch_testing.py
```

### Calculate Metrics:
```bash
python analysis/calculate_metrics.py
```

### Metrics Included:
- âœ… Agreement Rate (% successful negotiations)
- âœ… Rounds to Convergence (average rounds until agreement)
- âœ… Utility Scores (calculated from value functions)
- âœ… Language Complexity (word count, readability, vocabulary richness)
- âœ… Persona Comparisons (statistics by persona pairing)

**All metrics use standard academic methods, NOT LLM opinions!**

## Next Steps

- [ ] Statistical significance testing (t-tests, ANOVA)
- [ ] Data visualization (charts, graphs)
- [ ] Qualitative analysis (manual transcript review)
- [ ] Write report (abstract, methodology, results, discussion)
